upper = list(continuous = "density", combo = "box_no_facet"),
lower = list(continuous = "points", combo = "dot_no_facet")
)
View(tips)
#Modificamos los colores de los  puntos. Ojo cambia
#cambia también el color de todas las líneas
scatterplotMatrix(datos_n,col="red" )
#Ahora cambiamos el color de la línea de regresión robusta para
#cada par.
scatterplotMatrix(datos_n,
regLine = list(method=lm, lty=1, lwd=2, col="green"),
col="black" )
#A continuación cambiamos el color de la línea gruesa (curvilínea)
# que es un suavizador de regresión no paramétrico (el valor predeterminado es un gam
#"GENERALIZED ADDITIVE MODEL")
scatterplotMatrix(datos_n,smooth=list(smoother=loessLine, spread=TRUE,
lty.smooth=1, lwd.smooth=1.5,
lty.spread=3, lwd.spread=1,
col.smooth="red",
col.spread="blue"),
regLine = list(method=lm, lty=1, lwd=2, col="green"),
col="black" )
#Tambien es posible hacer una gráfica por grupos
scatterplotMatrix(datos_n, groups = as.factor(datos_n$cyl), by.groups=TRUE)
View(datos)
d1 <- ggplot(datos, aes(x="", y="mpg"))+geom_boxplot()
d2 <- ggplot(datos, aes(x="",y="drat"))+geom_boxplot()
d1
d2
d1 <- ggplot(datos, aes(x="1", y="mpg"))+geom_boxplot()
d2 <- ggplot(datos, aes(x="1",y="drat"))+geom_boxplot()
d1
d2
d1 <- ggplot(datos, aes(x="cyl", y="mpg"))+geom_boxplot()
d2 <- ggplot(datos, aes(x="cyl",y="drat"))+geom_boxplot()
d1
d2
#Un ejemplo con ggplot2
library(ggplot2)
d1 <- ggplot(datos, aes(x="cyl", y="mpg"))+geom_boxplot()
d2 <- ggplot(datos, aes(x="cyl",y="drat"))+geom_boxplot()
d1 <- ggplot(datos, aes(x="", y=mpg))+geom_boxplot()
d2 <- ggplot(datos, aes(x="",y=drat))+geom_boxplot()
d1
d2
d4 <- ggplot(datos, aes(x="",y=qsec))+geom_boxplot()
g12 <- ggplot(datos, aes(x=mpg, y=drat))+geom_point()
g12
g11 <- ggplot(datos, aes(x="", y=mpg))+geom_boxplot()
g22 <- ggplot(datos, aes(x="",y=drat))+geom_boxplot()
g33 <- ggplot(datos, aes(x="",y=wt))+geom_boxplot()
g44 <- ggplot(datos, aes(x="",y=qsec))+geom_boxplot()
g12 <- ggplot(datos, aes(x=mpg, y=drat))+geom_point()
g13 <- ggplot(datos, aes(x=mpg, y=wt))+geom_point()
g14 <- ggplot(datos, aes(x=mpg, y=qsec))+geom_point()
g21 <- ggplot(datos, aes(x=drat, y=mpg))+geom_point()
g23 <- ggplot(datos, aes(x=drat, y=wt))+geom_point()
g24 <- ggplot(datos, aes(x=drat, y=qsec))+geom_point()
g31 <- ggplot(datos, aes(x=wt, y=mpg))+geom_point()
g32 <- ggplot(datos, aes(x=wt, y=drat))+geom_point()
g34 <- ggplot(datos, aes(x=wt, y=qsec))+geom_point()
g31 <- ggplot(datos, aes(x=qsec, y=mpg))+geom_point()
g32 <- ggplot(datos, aes(x=qsec, y=drat))+geom_point()
g34 <- ggplot(datos, aes(x=qsec, y=wt))+geom_point()
#Unimos
library(grid)
library(gridExtra)
g31 <- ggplot(datos, aes(x=wt, y=mpg))+geom_point()
g32 <- ggplot(datos, aes(x=wt, y=drat))+geom_point()
g34 <- ggplot(datos, aes(x=wt, y=qsec))+geom_point()
g41 <- ggplot(datos, aes(x=qsec, y=mpg))+geom_point()
g42 <- ggplot(datos, aes(x=qsec, y=drat))+geom_point()
g43 <- ggplot(datos, aes(x=qsec, y=wt))+geom_point()
grid.arrange(g11,g12,g13,g14,g21,g22,g23,g24,g31,g32,g33,g34,g41,g42,g43,g44, ncol=4,nrow=4)
install.packages("scatterplot3d") # Instalar
library("scatterplot3d") # cardar
#datos
data(iris)
head(iris)
#scatterplot3d()
# Basic 3d graphics
scatterplot3d(iris[,1:3])
# Change the angle of point view
scatterplot3d(iris[,1:3], angle = 55)
#Change the main title and axis labels
scatterplot3d(iris[,1:3],
main="3D Scatter Plot",
xlab = "Sepal Length (cm)",
ylab = "Sepal Width (cm)",
zlab = "Petal Length (cm)")
#Change the shape and the color of points
#The argument pch and color can be used:
scatterplot3d(iris[,1:3], pch = 16, color="steelblue")
#Change point shapes by groups
shapes = c(16, 17, 18)
shapes <- shapes[as.numeric(iris$Species)]
scatterplot3d(iris[,1:3], pch = shapes)
#Remove the box around the plot
scatterplot3d(iris[,1:3], pch = 16, color = colors,
grid=TRUE, box=FALSE)
#Change point colors by groups
colors <- c("#999999", "#E69F00", "#56B4E9")
colors <- colors[as.numeric(iris$Species)]
scatterplot3d(iris[,1:3], pch = 16, color=colors)
# 3D plot with the regression plane
scatter3d(x = sep.l, y = pet.l, z = sep.w)
# 3D plot with the regression plane
require(car)
scatter3d(x = sep.l, y = pet.l, z = sep.w)
install.packages("rgl")
#Con plotly
library(plotly)
mtcars$am[which(mtcars$am == 0)] <- 'Automatic'
mtcars$am[which(mtcars$am == 1)] <- 'Manual'
mtcars$am <- as.factor(mtcars$am)
fig <- plot_ly(mtcars, x = ~wt, y = ~hp, z = ~qsec, color = ~am, colors = c('#BF382A', '#0C4B8E'))
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
fig
fig
#datos
data(iris)
head(iris)
iris$densidad_n <- rnorm(length(iris$Sepal.Length), mean=0.7, sd=0.1)
View(iris)
View(iris)
iris$nva <- paste(iris$Species, iris$Sepal.Length, sep=".")
View(iris)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
ufos <- read_csv("tec_documentos_plataforma/semana_19/Activities_2/Activities/01-Stu_UFO_Pipes/Unsolved/ufo.csv")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
students <-read_csv("../resources/students.csv")
schools <- read_csv("schools.csv")
students <-read_csv("../resources/students.csv")
schools <- read_csv("../resources/schools.csv")
data2 = left_join(students, schools, by=c("school_name"))
data2 %>% head()
---
title: "Pipe Dreams Are Made of These"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Dependency
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
```
### Read CSV file
```{r}
students <-read_csv("../resources/students.csv")
schools <- read_csv("../resources/schools.csv")
```
### Preview tibble
```{r}
students %>% head()
```
```{r}
schools %>% head()
```
#### Join two tibbles
```{r}
data2 = left_join(students, schools, by=c("school_name"))
data2 %>% head()
```
### Total Number of Schools
```{r}
school_count <- students$school_name %>%
unique() %>%
length()
school_count
```
### Total Number of Students
```{r}
student_count <-  students %>% nrow()
student_count
```
### Average reading and math scores
```{r}
mean_reading_score <- summarize(students, mean(reading_score))
mean_math_score <- summarize(students, mean(math_score))
```
### Calculate the percentage of students with passing reading scores, i.e. over 70%.
```{r}
percentage_passing_reading <- students %>%
filter(reading_score > 70) %>%
nrow() * 100 / student_count %>%
round(2)
percentage_passing_reading
```
### Calculate the percentage of students with passing math scores, i.e. over 70%.
```{r}
percentage_passing_math <-  students %>%
filter(math_score > 70) %>%
nrow() * 100 / student_count %>%
round(2)
percentage_passing_math
```
### Calculate the overall passing rate, i.e. the average of math and reading passing percentages
```{r}
overall_passing_rate <- (percentage_passing_math + percentage_passing_reading) / 2
overall_passing_rate
```
### Calculate the average math and reading scores by school
```{r}
students %>%
group_by(school_name) %>%
summarize(avg.reading=mean(reading_score), avg.math=mean(math_score))
```
### Calculate the average math and reading scores by grade level at each school
```{r}
students %>%
group_by(school_name, grade) %>%
summarize(avg.reading=mean(reading_score), avg.math=mean(math_score))
```
```{r}
total_budget <- schools %>%
summarize(sum(budget))
```
### Display data
```{r}
paste("School count: ", school_count)
paste("Student count: ", student_count)
paste("Total budget: ", total_budget)
paste("Average reading score: ", mean_reading_score)
paste("Average math score: ", mean_math_score)
paste("% passing reading: ", percentage_passing_reading)
paste("% passing math: ", percentage_passing_math)
paste("Overall passing rate: ", overall_passing_rate)
```
### Use sapply() to convert data type
```{r}
# YOUR CODE HERE
```
### Create Tibble of District Summary
```{r}
# YOUR CODE HERE
```
### Display summary of district-wide data
```{r}
# YOUR CODE HERE
```
### Create a per-school summary
```{r}
# YOUR CODE HERE
```
school_count <- students$school_name %>%
unique() %>%
length()
school_count
student_count <-  students %>% nrow()
student_count
mean_reading_score <- summarize(students, mean(reading_score))
mean_math_score <- summarize(students, mean(math_score))
mean_reading_score <- summarize(students, mean(reading_score))
mean_math_score <- summarize(students, mean(math_score))
percentage_passing_reading <- students %>%
filter(reading_score > 70) %>%
nrow() * 100 / student_count %>%
round(2)
percentage_passing_reading
percentage_passing_math <-  students %>%
filter(math_score > 70) %>%
nrow() * 100 / student_count %>%
round(2)
percentage_passing_math
overall_passing_rate <- (percentage_passing_math + percentage_passing_reading) / 2
overall_passing_rate
students %>%
group_by(school_name) %>%
summarize(avg.reading=mean(reading_score), avg.math=mean(math_score))
students %>%
group_by(school_name, grade) %>%
summarize(avg.reading=mean(reading_score), avg.math=mean(math_score))
total_budget <- schools %>%
summarize(sum(budget))
paste("School count: ", school_count)
paste("Student count: ", student_count)
paste("Total budget: ", total_budget)
paste("Average reading score: ", mean_reading_score)
paste("Average math score: ", mean_math_score)
paste("% passing reading: ", percentage_passing_reading)
paste("% passing math: ", percentage_passing_math)
paste("Overall passing rate: ", overall_passing_rate)
# YOUR CODE HERE
total_budget <- total_budget %>% sapply(as.numeric)
mean_math_score <- mean_math_score %>% sapply(as.numeric)
mean_reading_score <- mean_reading_score %>% sapply(as.numeric)
# YOUR CODE HERE
district_summary <- tribble(
~Total.Schools, ~Total.Students, ~Total.Budget, ~Avg.Math, ~Avg.Reading, ~Percent.Passing.Math, ~Percent.Passing.Reading, ~Overall.Passing,
school_count, student_count, total_budget[[1]], mean_math_score[[1]], mean_reading_score[[1]], percentage_passing_reading, percentage_passing_math[[1]], overall_passing_rate
)
knitr::opts_chunk$set(echo = TRUE)
total_budget <- schools %>%
summarize(sum(budget))
total_budget
# YOUR CODE HERE
district_summary <- tribble(
~Total.Schools, ~Total.Students, ~Total.Budget, ~Avg.Math, ~Avg.Reading, ~Percent.Passing.Math, ~Percent.Passing.Reading, ~Overall.Passing,
school_count, student_count, total_budget[[1]], mean_math_score[[1]], mean_reading_score[[1]], percentage_passing_reading, percentage_passing_math[[1]], overall_passing_rate
)
# YOUR CODE HERE
district_summary
#Importando los datos csv
datos <- read.csv(file.choose())
# Paso 2: validar los datos para su corrección
#______________________________________________________
dim(datos)
head(datos, 10)
#Ver las 3 filas finales del conjunto de datos
tail(datos, 3)
# Calcular la media de la población
mean(datos$CoffeeCupsPerDay)
mean(Datos[,2])
# Paso 1 - Importar datos
#_______________________________________________________
datos <- read.csv(file.choose())
# Cantidad de filas y columnas
dim(datos)
#Ver las 10 filas iniciales del conjunto de datos
head(datos, 10)
#Ver las 3 filas finales del conjunto de datos
tail(datos, 3)
# Calcular la media de la población
mean(datos$CoffeeCupsPerDay)
#Graficamos todas las observaciones en los datos
hist(datos$CoffeeCupsPerDay, col="pink", main="Histograma del consumo de tazas de café por día",
xlab="Número de tazas de café por día")
abline(v=2.89, col="red", lty=1)
s10 <- c()
n=9000
for (i in 1:n) {
s10[i]=mean(sample(datos$CoffeeCupsPerDay, 10, replace = TRUE))
}
hist(s10, col="lightgreen", main="Tamaño de la muestra =10", xlab="Número de tazas de café")
abline(v=mean(s10), col="Red")
abline(v=2.89, col="blue")
# Tomaremos tamaño de muestra size = 30, 50 y 500 sample = 9000
# Calcular la media aritmética y trazar la media de la muestra 9000 veces
s30 <- c()
s50 <- c()
s500 <- c()
n=9000
for(i in 1:n){
s30[i] = mean(sample(datos$CoffeeCupsPerDay), 30, replace=TRUE)
S50[i] = mean(sample(datos$CoffeeCupsPerDay, 50, replace=TRUE))
S500[i]= mean(sample(datos$CoffeeCupsPerDay, 500, replace = TRUE))
}
for(i in 1:n){
s30[i] = mean(sample(datos$CoffeeCupsPerDay), 30, replace=TRUE)
s50[i] = mean(sample(datos$CoffeeCupsPerDay, 50, replace=TRUE))
s500[i]= mean(sample(datos$CoffeeCupsPerDay, 500, replace = TRUE))
}
hist(s30, col="lightblue", main="Muestra de tamaño 30", xlab="tazas de café por día",
ylab="Frecuencia")
abline(v=mean(S30), col="red")
hist(s30, col="lightblue", main="Muestra de tamaño 30", xlab="tazas de café por día",
ylab="Frecuencia")
abline(v=mean(s30), col="red")
par(mfrow=c(1,3))
hist(s30, col="lightblue", main="Muestra de tamaño 30", xlab="tazas de café por día",
ylab="Frecuencia")
abline(v=mean(s30), col="red")
# Tomaremos tamaño de muestra size = 30, 50 y 500 sample = 9000
# Calcular la media aritmética y trazar la media de la muestra 9000 veces
s30 <- c()
s50 <- c()
s500 <- c()
n=9000
for(i in 1:n){
s30[i] <- mean(sample(datos$CoffeeCupsPerDay, 30, replace=TRUE))
s50[i] <- mean(sample(datos$CoffeeCupsPerDay, 50, replace=TRUE))
s500[i] <- mean(sample(datos$CoffeeCupsPerDay, 500, replace=TRUE))
}
par(mfrow=c(1,3))
hist(s30, col="lightblue", main="Tamaño de la muestra=30", xlab = "Número de tazas de café al día",
ylab="Frecuencia")
abline(v=mean(s30), col="red")
hist(s50, col="lightgreen", main="Tamaño de la muestra=50", xlab="Número de tazas de café al día",
ylab="Frecuencia")
abline(v=mean(s50), col="red")
hist(s500, col="orange", main="Tamaño de la muestra=500", xlab="Número de tazas de café al día",
ylab="Frecuencia")
abline(v=mean(s500), col="red")
curve(x^2, -10, 10, col = blue)
curve(x^2, -10, 10, col = "blue")
curve(x^2, -2, 2, col="red", add=T)
curve(x^2, -10, 10, col = "blue")
par(mfrow=c(3,3))
curve(x^2, -10, 10, col = "blue")
curve(x^2, -2, 2, col="red")
par(mfrow=c(3,2))
curve(x^2, -10, 10, col = "blue")
curve(x^2, -2, 2, col="red")
par(mfrow=c(3,1))
curve(x^2, -10, 10, col = "blue")
curve(x^2, -2, 2, col="red")
curve(x^2, 0,2, col="green", add=T)
curve(x^2, -1,1, col="purple")
curve(x^2, 0,1, col="pink", add=T)
#Let's fix the working directory
setwd("tec_documentos_plataforma/tareas/tarea_15/data")
#Lets import data
data <- read.csv("")
data <- read.csv("JC-202011-citibike-tripdata.csv", heaheader = T, stringsAsFactors = F)
data <- read.csv("JC-202011-citibike-tripdata.csv", header = T, stringsAsFactors = F)
View(data)
#Let's create a vector of dates
dates <- c(202011, 202010, 202009,202008,202007, 202006,202005,202004,202003,202002,202001,201912,201911)
#Import 12 files into a list
lista <- list()
for(i in 1:13){
#Create a text chain with the name of eac file
name_file <- paste0("JC-",dates[i],"-citibike-tripdata.csv")
lista[i]<- read.csv(name_file, header = T, stringsAsFactors = F)
}
lista[1]
View(data)
View(lista)
#Import 12 files into a list
lista <- list()
for(i in 1:13){
#Create a text chain with the name of eac file
name_file <- paste0("JC-",dates[i],"-citibike-tripdata.csv")
lista[[i]]<- read.csv(name_file, header = T, stringsAsFactors = F)
}
lista[1]
names_comparison <- c()
#Let's check the name of the features of each dataframe
for (i in 1:12) {
names_comparison[i]<- names(lista[[i]])==names(lista[[i+1]])
}
warnings()
print(length(colnames(lista[[i]])))
names_comparison <- c()
#Let's check the name of the features of each dataframe
for (i in 1:12) {
print(length(colnames(lista[[i]])))
print(length(colnames(lista[[i+1]])))
names_comparison[i]<- names(lista[[i]])==names(lista[[i+1]])
}
#Let's call the comparison vector
names_comparison
#Since the 13 data frames has the same columns names it is posible to join them in one unique
#dataframe
data <- NULL
for (i in 1:length(lista)) {
print(i)
}
for (i in 1:length(lista)) {
data <- rbind.data.frame(data, lista[[i]])
}
View(data)
n <- nrow(data)
data <- data %>% distinct()
#Now lets remove duplcated data in the final dataframe
library(dplyr)
n <- nrow(data)
data <- data %>% distinct()
m <- nrow(data)
#Lets check hpw many rows we drop
n-m
#Lets check how many rows we drop
print(paste("We drop", n-m, "repeated rows", sep=" "))
#Citybike data managing and cleaning
#Let's fix the working directory
setwd("tec_documentos_plataforma/tareas/tarea_15/data")
#Lets import data
JC-202011-citibike-tripdata
data <- read.csv("JC-202011-citibike-tripdata.csv", header = T, stringsAsFactors = F)
#Let's create a vector of dates
dates <- c(202011, 202010, 202009,202008,202007, 202006,202005,202004,202003,202002,202001,201912,201911)
#Import 12 files into a list
lista <- list()
for(i in 1:13){
#Create a text chain with the name of eac file
name_file <- paste0("JC-",dates[i],"-citibike-tripdata.csv")
lista[[i]]<- read.csv(name_file, header = T, stringsAsFactors = F)
}
names_comparison <- c()
#Let's check the name of the features of each dataframe
for (i in 1:12) {
print(length(colnames(lista[[i]])))
print(length(colnames(lista[[i+1]])))
names_comparison[i]<- names(lista[[i]])==names(lista[[i+1]])
}
#Let's call the comparison vector
names_comparison
#Since the 13 data frames has the same columns names it is posible to join them in one unique
#dataframe
data <- NULL
for (i in 1:length(lista)) {
data <- rbind.data.frame(data, lista[[i]])
}
#Now lets remove duplcated data in the final dataframe
library(dplyr)
n <- nrow(data)
data <- data %>% distinct()
m <- nrow(data)
#Lets check how many rows we drop
print(paste("We drop", n-m, "repeated rows", sep=" "))
#Save the final dataframe
write.csv(data, "citybike_data.csv")
#Save the final dataframe
setwd("C:/Users/avalo/OneDrive/Documentos/tec_documentos_plataforma/tareas/tarea_15/CityBike_AAV")
write.csv(data, "citybike_data.csv")
View(data)
